{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Circle\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-755404f49471>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# print(files)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Filename : '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "test_faces_path = os.getcwd()+'/test_faces/'\n",
    "check = os.path.isdir(test_faces_path)\n",
    "if (not check):\n",
    "    os.mkdir(test_faces_path)\n",
    "\n",
    "# draw each face separately\n",
    "def draw_box(file, result_list):\n",
    "    \n",
    "    # load the image\n",
    "    data = plt.imread(file)\n",
    "    \n",
    "    # plot each face as a subplot\n",
    "    for i in range(len(result_list)):\n",
    "        \n",
    "        # get coordinates\n",
    "        x1, y1, width, height = result_list[i]['box']\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        \n",
    "        # define subplot\n",
    "        plt.subplot(1, len(result_list), i+1)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # plot face\n",
    "        plt.imshow(data[y1:y2, x1:x2])\n",
    "        \n",
    "        # check if directory is present or not - if not then creates one\n",
    "        filename = 'img'+str(i)+'.jpg'\n",
    "\n",
    "        #writes the detected faces in specified directory\n",
    "        cv2.imwrite(test_faces_path+filename, data[y1:y2, x1:x2])\n",
    "        \n",
    "    # show the plot\n",
    "    plt.show()\n",
    "\n",
    "def convert_to_jpg(filename):\n",
    "    im = Image.open(filename)\n",
    "    rgb_im = im.convert('RGB')\n",
    "    name = filename[:-4]+'.jpg'\n",
    "    rgb_im.save(name)\n",
    "    return name\n",
    "\n",
    "PATH = os.getcwd()+\"\\\\class_photo\\\\\"\n",
    "# print('Input Image Name')\n",
    "files = os.listdir(PATH)\n",
    "# print(files)\n",
    "filename = files[0]\n",
    "print('Filename : ',filename)\n",
    "\n",
    "print('Checking extension...')\n",
    "ext = filename[-3:]\n",
    "if ext != 'jpg' :\n",
    "    filename = convert_to_jpg(filename)\n",
    "\n",
    "path = os.getcwd()+'\\\\class_photo\\\\'\n",
    "path_img = os.path.join(path,filename)\n",
    "print('Path: ',path_img)\n",
    "\n",
    "print(\"Loading and Displaying image... \")\n",
    "# load image from file\n",
    "pixels = plt.imread(path_img)\n",
    "# Displaying image\n",
    "plt.imshow(pixels)\n",
    "\n",
    "print(\"Creating MTCNN object for detection...\")\n",
    "# create the detector, using default weights\n",
    "detector = MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "# print(\"Faces: \",faces)\n",
    "print('Number of faces detected: ',len(faces))\n",
    "# Deleting all previous images\n",
    "# print(test_faces_path)\n",
    "[os.remove(os.path.join(test_faces_path,file)) for file in os.listdir(test_faces_path) if file.endswith('.jpg')]\n",
    "\n",
    "draw_box(path_img, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop a classifier for the Faces Dataset\n",
    "from random import choice\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import pyplot\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samkit\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('facenet_keras.h5')\n",
    "\n",
    "class_model = pickle.load(open('svm_trained_classifier.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_faces(directory):\n",
    "    test = list()\n",
    "    # enumerate files\n",
    "    for filename in listdir(directory):\n",
    "        # path\n",
    "        path = directory + filename\n",
    "        # get face\n",
    "        image = Image.open(path)\n",
    "        image = image.convert('RGB')\n",
    "        image = image.resize((160, 160))\n",
    "        face_array = np.asarray(image)\n",
    "        \n",
    "        embeddings = get_embedding(model,face_array)\n",
    "        # store\n",
    "        test.append(embeddings)\n",
    "    return np.asarray(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, face_pixels):\n",
    "    # scale pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    # standardize pixel values across channels (global)\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    # transform face into one sample\n",
    "    samples = expand_dims(face_pixels, axis=0)\n",
    "    # make prediction to get embedding\n",
    "    #yhat =  model.embeddings(samples)\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.getcwd()+\"/test_faces/\"\n",
    "\n",
    "test = load_faces(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "test = in_encoder.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load faces\n",
    "data = load('faces-dataset.npz')\n",
    "testX_faces = data['arr_2']\n",
    "# print('testX_faces : ',testX_faces)\n",
    "# load face embeddings\n",
    "data = load('faces-embeddings.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy = out_encoder.transform(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_students = list()\n",
    "for i in range(test.shape[0]):\n",
    "    random_face_emb = test[i]\n",
    "    random_face_emb = random_face_emb.reshape((128,))\n",
    "    samples = expand_dims(random_face_emb, axis=0)\n",
    "    # print(samples)\n",
    "    # print(samples.shape)\n",
    "    yhat_class = class_model.predict(samples)\n",
    "    yhat_prob = class_model.predict_proba(samples)\n",
    "    class_index = yhat_class[0]\n",
    "    class_probability = yhat_prob[0,class_index] * 100\n",
    "\n",
    "    predict_names = out_encoder.inverse_transform(yhat_class)\n",
    "    # print(predict_names)\n",
    "    #print('Predicted: ',predict_names,' (',str(class_probability[0])[1:7],')')\n",
    "    present_students.append(predict_names[0])\n",
    "#     print('Predicted ',i+1,' : ',predict_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baccha',\n",
       " 'Varun_Vasani',\n",
       " 'Aryan Verma',\n",
       " 'Samkit Saraf',\n",
       " 'Varun Kumar Nyalapelli']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "present_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aryan_Verma_B255', 'Samkit_Saraf_B241', 'Varun_Kumar_B245', 'Varun_Vasani_B252']\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "PATH = os.getcwd()+'\\\\dataset\\\\train\\\\'\n",
    "student_names = os.listdir(PATH)\n",
    "print(student_names)\n",
    "# student_names =[\"varun_kumar_nyalapelli\", \"Varun_Vasani\", \"Samkit Saraf\", \"Aryan Verma\", \"RiteshRana\", \"ShashwatTare\",\n",
    "#                \"HussianChaiwala\", \"AdityaShankar\", \"Carry\", \"Baccha\"]\n",
    "\n",
    "df = pd.DataFrame({\"name\":student_names})\n",
    "\n",
    "df.insert(1,\"attendance\",0)\n",
    "\n",
    "df['attendance'] = df['name'].apply(lambda x: 1 if x in present_students else 0)\n",
    "\n",
    "PATH = os.getcwd()+\"\\\\attendance_sheets\\\\\"\n",
    "if (not os.path.isdir(PATH)):\n",
    "    os.mkdir(PATH)\n",
    "\n",
    "df.to_excel(PATH+\"attendance_sheet.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[os.remove(os.path.join(PATH,file)) for file in os.listdir(PATH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
